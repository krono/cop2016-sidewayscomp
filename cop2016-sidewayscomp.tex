%
%  Fast Sideways Composition, for COP 2016
%
% Confirmation Number:» 
% Submission Passcode:» 
% MAX 6 PAGES
%
\RequirePackage[l2tabu, orthodox]{nag}
\PassOptionsToPackage{final}{graphics}
\documentclass[preprint,english,10pt,nonatbib]{sigplanconf}
\usepackage{myheader}
\addbibresource{references.bib}
\newacronym{api}{\textsc{api}}{application programming interface}
\newacronym{aop}{\textsc{aop}}{aspect-oriented programming}
\newacronym{cop}{\textsc{cop}}{context-oriented programming}
\newacronym{oop}{\textsc{oop}}{object-oriented programming}
\newacronym{oo}{\textsc{oo}}{object-oriented}
\newacronym{dsl}{\textsc{dsl}}{domain-specific language}
\newacronym{jit}{\textsc{jit}}{just-in-time}
\newacronym{vm}{\textsc{vm}}{virtual machine}
\newacronym{ffi}{\textsc{ffi}}{foreign-function interface}

\begin{document}
\conferenceinfo{COP '16}{July 19, 2016, Rome, Italy}
\copyrightyear{2016}
\copyrightdata{978-1-nnnn-nnnn-n/16/07}
\copyrightdoi{nnnnnnn.nnnnnnn}

\publicationrights{licensed}     % this is the default

\titlebanner{DRAFT \--- not for distribution \--- DRAFT}        % These are ignored unless
\preprintfooter{Submitted to COP'16}

\title{Optimizing Sideways Composition}
\subtitle{Fast Context-oriented Programming in ContextPyPy}

% \authorinfo{Tobias Pape}
%            {Hasso Plattner Institute\\ University of Potsdam, Germany}
%            {tobias.pape@hpi.uni-potsdam.de}
% \authorinfo{Tim Felgentreff}
%            {Hasso Plattner Institute\\ University of Potsdam, Germany}
%            {tim.felgentreff@hpi.uni-potsdam.de}
% \authorinfo{Carl Friedrich Bolz}
%            {King's College, London}
%            {cfbolz@gmx.de}
\authorinfo{Tobias Pape\textsuperscript{*} \and Tim Felgentreff\textsuperscript{*\textdagger} \and Robert Hirschfeld\textsuperscript{*\textdagger}}
           {\textsuperscript{*}Hasso Plattner Institute, University of Potsdam, Germany\\
           \textsuperscript{\textdagger}Communications Design Group (CDG), SAP Labs, USA\\
           \textsuperscript{\textdagger}Viewpoints Research Institute, USA}
           {\{firstname\}.\{lastname\}@hpi.uni-potsdam.de}

\maketitle

\begin{abstract}
  The prevalent way of code sharing in most of the current object systems is
  static and/or single inheritance, both are limiting. Sideways composition
  provides a technique to reduce their limitations. \Ac{cop} notably applies
  sideways composition to achieve better modularity. However, most \ac{cop}
  implementations have a substantial performance overhead. This is partly
  because weaving and execution of layered methods violate common assumptions
  about lookup. Meta-tracing \ac{jit} compiler have unique characteristics that
  can alleviate the performance overhead, as they can treat lookup
  differently.\\
  We suggest that meta-tracing \ac{jit} compilers are good at optimizing
  sideways composition and give initial results. Furthermore, we show that
  hints for the \ac{jit} compiler in a \ac{cop} implementation can improve
  performance further.
  \end{abstract}

\category{CR-number}{subcategory}{third-level}

\keywords
context-oriented programming,
meta-tracing \acs{jit} compilers,
optimization,
virtual machines,
PyPy

\section{Introduction}

\paragraph*{Contributions}

\begin{itemize}
\item <<We show that metatracing not only makes python fast, but also COP/SC
  faster>>
\item <<We show that \emph{promote}(TBD) can further improve stuff and
  elimitates COP overhead when COP Layers are present but not in use>>
\end{itemize}

\section{<<Background: COP, COPSurvey, MetaTracing>>}

\subsection{The Performance of COP}
\label{sec:performance-cop}
\ac{cop} as a modularity mechanism to dynamically adapt behavior at run-time has
been demonstrated to be useful in a variety of scenarios. Beyond its original
motivation for dynamically adapting systems based on environmental factors such
as battery level, geolocation, or time of day~\todo{cite}, \ac{cop} has also
been applied to provide safety in the development of live
systems~\cite{lincke+:2012:scoping-changes} or to let multiple conflicting
versions of programming interfaces co-exist~\todo{cite my talk cop 2013}. 

However, as with many abstraction mechanisms, \ac{cop} comes with some overhead,
a fact that has been repeatedly recognized. Context layer aware method lookup
requires additional operations at run-time. Most \ac{cop} extensions to dynamic
languages use the host languages meta-programming facilities to redirect method
dispatch, whereas statically compiled languages require additional compilation
steps to construct data structures to track layer activation states at
run-time. Both of these solutions come with considerable performance decrease
from 75 \% up to 99 \%~\cite{appeltauer+:2009:comparison-context-oriented}.

So far, attempts to apply traditional compiler and optimization techniques have
proven to be difficult and can only reduce the performance overhead in some
cases. A common approach is to shift the performance impact to the layer
activation time. ContextAmber~\cite{springer2015efficient} optimistically
flattens layered methods when the layer composition changes to achieve near
native performance during execution. An extension to the C++ configuration
management system Elektra~\cite{Raab:2014:PEE:2637066.2637074} make use of
extensive code generation and caching of the active layer composition to
minimize the performance impact of running with active layers in a tight
loop. Both approaches nearly eliminate the performance impact of layers when the
composition changes rarely, but at the cost of reduced performance for
applications where the layer composition may change frequently. \ac{vm}
facilities such as Java's INVOKEDYNAMIC instruction provide only minimally
improved performance compared to an implementation using language-level caching
facilities, albeit using less code and a simplified architecture.

\subsection{Meta-Tracing JIT}
\label{sec:meta-tracing-jit}

\section{<<Solution: Sideways-composition and metatracing>>}

We propose that meta-tracing \ac{jit} compilers can reduce the overhead of
sideways composition and \ac{cop}, and that \emph{promoting} the composition of
active layers can reduce the overhead even further.

\subsection{Employing a meta-tracing \protect\acs{jit}}
\Acl{cop} employs sideways composition to inject context-dependent behavioral
changes into an existing hierarchy of behavior. These hierarchies are typically
defined by the static and/or single inheritance of object systems. These
hierarchies are typically important for execution time performance, as they
form the basis for \emph{lookup}.

Most execution environments, such as \acp{vm} for dynamic object-oriented
languages, assume that those hierarchies change rarely and hence lookup can be
fast. However, using sideways composition to alter behavior invalidates this
assumption. Especially, since \ac{cop} explicitly redefines lookup based on
currently active layers; the composition of currently active layers becomes
\emph{crucial} for calculating the lookup in the dynamic extent of executed
code. If this composition stays the same, lookup stays the same, if it changes,
lookup may change. Execution environments typically have to decide, whether to
always re-exercise the lookup for every method under the active layers, or
cache (and invalidate) lookup information when the composition of active layers
changes. For example in the sequence
\begin{lstlisting}
-- active layers: §\(\emptyset\)§
method1()
  activate(layer1)
    method2()
  deactivate(layer1)
\end{lstlisting}
a \ac{cop} implementation typically uses one of the following two strategies:
\begin{enumerate}
\item run the lookup for \lstinline|method1()| under the active layers
  \(\emptyset\) and the lookup for \lstinline|method()| under the active layers
  \([\)\lstinline|layer1|\(]\), or
\item use cached lookup information for \lstinline|method1()|, switch cached
  lookup information due to change in active layers, use (new) cached lookup
  information for \lstinline|method2()|.
\end{enumerate}
Both cases produces a performance impact either on every lookup or on every
layer change.

With meta-tracing \ac{jit} compilers, however, this effect is much less
severe. Although rarely-changing lookup still is helpful for its operation, a
change in lookup \--- for example induced by a layer activation \--- can be
anticipated and be accounted for.

Thus, with a properly instructed meta-tracing \ac{jit} compiler, a third option
becomes available. At points in the execution where the composition of active
layers becomes important, a \emph{guard} ensures that this composition did not
change. While counter-intuitive at first, this actually is a benefit. When a
certain different composition has been encountered often enough at the guard,
the meta-tracing \ac{jit} compiler will introduce a \emph{bridge} into a new
part of a trace, in which \emph{this} different composition can be assumed not
to change, and lookup can be optimized accordingly. Note that this resembles
strategy 2 above, but is implicit and actually guided by the \ac{jit} compiler.
Therefore, the actual \ac{cop} implementation does not have to manage the
caching information when altering the lookup information, saving both execution
time and implementation complexity.

\subsection{Promoting the compositions of active layers}

The compositions of active layers is crucially important for the lookup in
\ac{cop}, and all strategies above reflect this. However, only the
language-level implementation of \ac{cop} actually knows about the
composition's importance, and even for meta-tracing \ac{jit} compiler's
strategy, the \ac{jit} compiler first hast to become aware of the fact that the
composition is \--- indeed \--- important for its trace. Yet, the \ac{jit}
compile can only apply heuristics to identify the composition as
trace-important.

This situation is commonly known when implementing \acp{vm} that use a
meta-tracing \ac{jit} compiler. Based on the value of a certain object it may
be desirable to \emph{specialize} traces to these values (essentially what
happened above with the guard and the bridge).
Implementers can chose to \emph{promote}~\cite[\S
3.1]{bolz+:2011:runtime-feedback} such an object and the \ac{jit} compiler will
ensure that traces are actually specialized to the object's values,  regardless
of wether the \ac{jit} compiler's \emph{heuristics} would result in the same
specialization or not. If applied carefully, this promotion can decrease
execution time.

Up until recently, this \emph{promotion} of objects had not been available to
language-level implementers of \ac{cop}. However, at the time of writing, one
\ac{vm} with meta-tracing \ac{jit} compiler (PyPy) exposes the \emph{promote}
functionality to the language-level as experimental features and it is possible
to use it for a \ac{cop} implementation. The composition of active layers can
now be promoted and the meta-tracing \ac{jit} compiler now ensures that (a) a
specialized traces exists for each encountered composition, and (b) within a
given trace, the composition wont change and can be relied upon. This
assumption now can be made when exercising lookup during execution, saving
execution time.


\section{<<Impl: ContextPy, VM interface, applevel promote>>}


\section{<<Eval: Benchmarks>>}


\def\idBox#1#2{%
\setlength{\fboxsep}{1pt}%
\colorbox[HTML]{#1}{\textcolor[gray]{0.9}{\rule[0.1pt]{0pt}{5pt}#2}}%
\xspace}



We evaluate... hypotheses..., as described in the introduction:
\begin{enumerate}
\item Sideways composition \emph{still} has a considerable impact on execution
  time. <<still<-> copsurvey>>
\item Tracing JITs can alleviate the performance impact of sideways composition.
\item <<applevel promote>>.
\end{enumerate}



We tested the first hypothesis by ....

We tested the second hypothesis by ....

We tested the third hypothesis by ....

% PYCKET-COPY - DO NOT USE VERBATIM
% Our evaluation compares \pycket with multiple configurations and systems on
% a variety of programs. We present the most important results and include full
% results in supplemental material.

\subsection{Setup}
\label{sec:setup}


\paragraph{System} We conducted the experiments on %
% MacBook Pro Tobi
an Intel Core i7-4850HQ at \SI{2.3}{\GHz} with \SI{6}{\mega\byte} cache and
\SI{16}{\giga\byte} of RAM. The machine ran Mac OS\,X 10.9.5.
%%%% Surface Tim??
%
%%%% Maxinchen
% an Intel Xeon E5-2650 (Sandy Bridge)  at \SI{2.8}{\GHz} with
% \SI{20}{\mega\byte} cache and \SI{16}{\giga\byte} of RAM. 
% Although virtualized on Xen, the machine was idle.
% The machine ran Ubuntu 14.04.1 LTS with a \SI{64}{\bit} Linux 3.2.0.
RPython as of revision
648874ef8243
 was used for <<pypypromote>>.

All benchmarks are single-threaded.


\paragraph{Implementations} %
~\idBox{377EB8}{\(\circ\)}, %
~\idBox{4DAF4A}{\(\bigtriangleup\)}, %
~\idBox{984EA3}{\(\square\)}, %
~\idBox{FF7F00}{\(+\)}, %
~\idBox{FF7F00}{\(\boxtimes\)}, %
~\idBox{E41A1C}{\(\)}, %

<<DeltaBlue/Violet/Red>>
\begin{itemize}
\item ContextPy with Python 2.7.5 on OS\,X
\item ContextPy with PyPy 5.0.1 on OS\,X
\item ContextPy with PyPyPromote (5.1.0-alpha0 648874ef8243) on OS\,X
\end{itemize}

and additionally for <<maltebench>>
\begin{itemize}
\item ContextJS with Chrome 50.0.2661.66 beta (64-bit) on OS\,X
\item << ContextJS Win10 Edge -- tim? >>
\item <<ContextJS Win10 Chrome -- tim?>>
\item <<(ContextJS Win10 Firefox -- tim?)>>
\end{itemize}

\paragraph{Methodology} 
% INITSIZE = 200000
% MAXSIZE = 1000000000
% TARGETTIME = 5.0 * 1000
For <<maltebench>>, every benchmark was with increasing size until a
measurement took at least 5 seconds; this matches the original
methodology~\cite{appeltauer+:2009:comparison-context-oriented}.Warm-up is
provided by the not measured runs.
% ITER_DEFAULT=${ITER:-5}
% SIZE_DEFAULT=${SITE:-20000}
% WARM_DEFAULT=${WARM:-2}
For <<DeltaBlue>>, every benchmark was run 5 times uninterrupted at highest
priority in a new process with additional 2 times prior to measurement.
The execution time was always measured \emph{in-system} and, hence, does not include start-up.
We show the arithmetic mean of all  runs along with
bootstrapped~\cite{davison+:1997:confidence-intervals} confidence intervals
for a \SI{95}{\percent} confidence level.

%\footnote{Raw figures can be  found as an appendix (\autoref{tab:all})}

\paragraph{Availability}  All of our benchmarks and infrastructure
 are available at <<TBD>>.


\subsection{Benchmarks}


\subsection{Threats to Validity}

OSX: SpeedStep cannot be disabled.

\section{Related Work}

\section{<<Conclusion/FW: Promising first results, application to other stuff necessary>>}

\acks
We gratefully acknowledge the financial support of HPI's Research School and
the Hasso Plattner Design Thinking Research Program (HPDTRP).
% Carl Friedrich
% Bolz is supported by the EPSRC \emph{Cooler} grant EP/K01790X/1.
LispWorks Ltd. kindly provided an evaluation license of
LispWorks\textsuperscript{\textregistered} 64-bit for Mac OS\,X for testing
purposes.

\printbibliography
% \appendix
% \section{Appendix Title}

\end{document}
